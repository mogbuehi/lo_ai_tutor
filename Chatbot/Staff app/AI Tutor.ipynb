{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b916bdb9-aff7-4847-80d5-d3951f2b5375",
   "metadata": {},
   "source": [
    "## AI Tutor\n",
    "- Upload csv with questions and generate and show\n",
    "    - Hints\n",
    "    - Walkthrough\n",
    "    - Solutions\n",
    "    - Edge Cases\n",
    " \n",
    "- UI\n",
    "- Integration ideas\n",
    "- Save chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249ce119-4047-4129-ad64-532bd71a9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "# ---------------------------------------------------\n",
    "# UI\n",
    "import gradio as gr\n",
    "\n",
    "# data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# plotting libs\n",
    "import altair as alt\n",
    "import matplotlib as plt\n",
    "\n",
    "# os and env libs\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path #read in txt files for clean bot \n",
    "\n",
    "# OpenAI python lib\n",
    "import openai\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "775f705f-84dc-48e8-a35e-f5a239f16797",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ai_tutor_sys_content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# messages, a list that will store all messages from session\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mai_tutor_sys_content\u001b[49m\n\u001b[0;32m     10\u001b[0m messages \u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: ai_tutor_sys_content}]\n\u001b[0;32m     12\u001b[0m index \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# a way to save the state of conversation\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ai_tutor_sys_content' is not defined"
     ]
    }
   ],
   "source": [
    "# ai_tutor chat function\n",
    "# when asked a python question, it should be able to create walkthrough, hints, \n",
    "\n",
    "# Load OpenAI API key:\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# read in context as a string and save it to `messages`, a list that will store all messages from session (up to token limit)\n",
    "ai_tutor_sys_content = Path('question clean prompt.txt').read_text()\n",
    "messages =[{\"role\": \"system\",\"content\": ai_tutor_sys_content}]\n",
    "\n",
    "index = [0] # a way to save the state of conversation\n",
    "\n",
    "# ai_tutor fxn\n",
    "def ai_tutor(prompt, history):\n",
    "    \n",
    "    #should I start with an assistant message to help the user get started?]\n",
    "    #list of messages that get passed in to start convo, will also save messages here\n",
    "    #f string to avoid prompt injection errors from user\n",
    "    messages.append({'role': 'user', 'content': f'{prompt}'}) \n",
    "  \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=1, #play with temp to get more factual responses\n",
    "        max_tokens=500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "    # Parsing out what we want to see displayed in the chatbot response\n",
    "    assistant_content = response['choices'][0]['message']['content']\n",
    "\n",
    "    # visual check for testing purposes\n",
    "    print(response) \n",
    "\n",
    "    #append messages memory  \n",
    "    messages.append(({'role':'assistant', 'content': assistant_content}))\n",
    "    \n",
    "    #add token counter and a way to handle hitting token limit. Prob summarizing previous assistant/student info into 2-4 sentences\n",
    "    \n",
    "    return assistant_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bf262-73e3-46cd-8b18-815b57f83de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function with Gradio ChatInterface function\n",
    "demo = gr.ChatInterface(\n",
    "    fn=ai_chat, \n",
    "    submit_btn = 'Submit', \n",
    "    retry_btn = 'Retry',\n",
    "    clear_btn = 'Clear',\n",
    "    title = 'AI Tutor',\n",
    "    #add a save convo button that can create html file that can then be printed like a pdf later\n",
    "    #and analyzed later/flash cards made\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722b690-1a94-41e3-8d3c-03d63b487567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a save bot that can parse ai_tutor responses and save the data in the appropriate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c51f4-b8e9-4f3e-932a-8da1fe2404ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_chat function\n",
    "# dynamically saves chat to a txt file in a certain format that can be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50c30d-73e5-4761-8eee-a90024bb8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when given a csv with just questions column, it should be able to fill out the walkthrough, hints, and solutions part of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2f718-b8e8-4648-a7ec-4a3df19e8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorization bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6edaf-402e-4b57-8ad9-620831a68992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5220f43a-ee23-4614-a697-0eb6ff55ac62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6e021-b160-4b92-b4ea-ab5bc6c5f0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
