{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d878d4-39c3-4d7a-9243-351d92f8bf16",
   "metadata": {},
   "source": [
    "# AI Tutor   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49370ff8-58bf-42a6-b82a-cc2fc3c7c886",
   "metadata": {},
   "source": [
    "1. Install and Import Gradio\r\n",
    "2. Create .env variable and add OpenAI sk\r\n",
    "3. Import OpenAI API code snips\r\n",
    "4. Load the SS question files as dataframe\r\n",
    "    - Output of dataframe \r\n",
    "5. Response functionality should refer to questions in the SS question file\r\n",
    "    - The bot should be able to read the file in the \r\n",
    "6. Save responses or csv in txt and use as context for sessions future\r\n",
    "7. Prompts engineering should be used to build a very very very good Python Data Science Tutor\r\n",
    "    - Preload the tutor wi/Datascienceth Python docu (future feature...use store memory and context in vector database?)mentation\r\n",
    "    - Preload the tutor with Data science documentation\r\n",
    "    - Tutor should be able to create a game\r\n",
    "8. Chatbot buttons\r\n",
    "    - Test me : uses database levels 1, 2, 3\r\n",
    "    - Track my progress: chatbot checks answer submission and judges if you got answer right or wrong\r\n",
    "    - Python flash cards built-in functionality\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9650bc-cffb-497c-97bf-fab439bdd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and Import Gradio, Pandas, Altair, Matplotlib, Os, and OpenAI (put this in \"bot_libs.py\" file and import it in one line as \"import bot_libs\" )\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import altair\n",
    "import matplotlib as plt\n",
    "import os\n",
    "import openai\n",
    "from pathlib import Path #read in txt files for clean bot \n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fcb13-f83f-4539-9db1-5e035d29d825",
   "metadata": {},
   "source": [
    "## Question Database\n",
    "Loading questions into script. Decide to use an LLM route to clean the data. Wasn't sure how they felt about scraping their website so went with this route instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05423fde-0675-4375-8593-0a954071948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Clean Bot function\n",
    "\n",
    "# Read question database\n",
    "load_dotenv()\n",
    "question_df = pd.read_csv('SS questions.csv')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\") ##This isn't working for some reason\n",
    "result = load_dotenv()\n",
    "print(result)\n",
    "# # Cleaning df (removing rows with #NAME?)\n",
    "# question_df = question_df[(question_df != '#NAME?').all(axis=1)]\n",
    "# Use GPT-3.5 to clean the data\n",
    "\n",
    "def column_clean_bot(prompt, system_content):\n",
    "    load_dotenv()\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\") ##This isn't working for some reason\n",
    "    messages = [{'role': 'system', 'content': system_content }]\n",
    "    messages.append({'role': 'user', 'content': prompt})\n",
    "    \n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=1, #play with temp to get more factual responses. max of 2\n",
    "        max_tokens=25,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    print(response) #print this in the CLI or notebook. This helps with understanding how the response json is structured for further customization\n",
    "    system_message = response['choices'][0]['message']['content'] #this is parsing the json file that is the response reponse. you take the first item in choices list (a list of dictionaries), go to message key, and then go to content key \n",
    "    # messages.append(({'role':'assistant', 'content': system_message})) \n",
    "    # messages = [] #this works as a reset to keep the conversation history clear when using in a loop\n",
    "    return system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df30f81-500f-402d-bc2d-83b347fca21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning question column\n",
    "system_content = Path('question clean prompt.txt').read_text()\n",
    "\n",
    "for index in range(len(question_df['question'])):\n",
    "    entry = question_df['question'][index]\n",
    "    \n",
    "    if entry == '#NAME?':\n",
    "        # at the index pick out the question short and python hint, save as variables\n",
    "        question = question_df['question'][index]  \n",
    "        hint = question_df['hint'][index]  \n",
    "        py_solution = question_df['python_solution'][index]\n",
    "        py_hint = question_df['python_hint'][index]\n",
    "\n",
    "        # insert those variables into multiline string that inserts variables into the string. save this multiling string as a variable\n",
    "        prompt = f'''\n",
    "        QUESTION:\n",
    "\n",
    "        \n",
    "        HINT:\n",
    "        {hint}\n",
    "        \n",
    "        PYTHON SOLUTION:\n",
    "        {py_solution}\n",
    "\n",
    "        PYTHON HINT:\n",
    "        {py_hint}\n",
    "\n",
    "        '''\n",
    "\n",
    "        # insert multiline string variable into prompt of column_clean_bot\n",
    "        cleaned_entry = column_clean_bot(prompt, system_content)\n",
    "\n",
    "        # save clean bot's guess as the new entry at this index\n",
    "        question_df['question'][index] = cleaned_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee0580-ebe1-41ca-9cca-689eb5fd5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning hint column\n",
    "system_content = Path('hint clean prompt.txt').read_text()\n",
    "\n",
    "for index in range(len(question_df['hint'])):\n",
    "    entry = question_df['hint'][index]\n",
    "    \n",
    "    if entry == '#NAME?' or entry == '' or entry == None:\n",
    "        # at the index pick out the question short and python hint, save as variables\n",
    "        question = question_df['question'][index]  \n",
    "        hint = question_df['hint'][index]  \n",
    "        py_solution = question_df['python_solution'][index]\n",
    "        py_hint = question_df['python_hint'][index]\n",
    "\n",
    "        # insert those variables into multiline string that inserts variables into the string. save this multiling string as a variable\n",
    "        prompt = f'''\n",
    "        QUESTION:\n",
    "        {question}\n",
    "\n",
    "        HINT:\n",
    "        \n",
    "        PYTHON SOLUTION:\n",
    "        {py_solution}\n",
    "\n",
    "        PYTHON HINT:\n",
    "        {py_hint}\n",
    "\n",
    "        '''\n",
    "\n",
    "        # insert multiline string variable into prompt of column_clean_bot\n",
    "        cleaned_entry = column_clean_bot(prompt, system_content)\n",
    "\n",
    "        # save clean bot's guess as the new entry at this index\n",
    "        question_df['hint'][index] = cleaned_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaeb5f9-266b-482b-854c-a3336b51216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning python hint column\n",
    "system_content = Path('python hint clean prompt.txt').read_text()\n",
    "\n",
    "\n",
    "for index in range(len(question_df['python_hint'])):\n",
    "    entry = question_df['python_hint'][index]\n",
    "    \n",
    "    if entry == '#NAME?' or entry == '' or entry == None:\n",
    "        # at the index pick out the question short and python hint, save as variables\n",
    "        question = question_df['question'][index]  \n",
    "        hint = question_df['hint'][index]  \n",
    "        py_solution = question_df['python_solution'][index]\n",
    "        py_hint = question_df['python_hint'][index]\n",
    "\n",
    "        # insert those variables into multiline string that inserts variables into the string. save this multiling string as a variable\n",
    "        multiline_string = f'''\n",
    "        QUESTION:\n",
    "        {question}\n",
    "\n",
    "        HINT:\n",
    "        {hint}\n",
    "        \n",
    "        PYTHON SOLUTION:\n",
    "        {py_solution}\n",
    "\n",
    "        PYTHON HINT:\n",
    "        \n",
    "\n",
    "        '''\n",
    "\n",
    "        # insert multiline string variable into prompt of column_clean_bot\n",
    "        cleaned_entry = column_clean_bot(prompt, system_content)\n",
    "\n",
    "        # save clean bot's guess as the new entry at this index\n",
    "        question_df['python_hint'][index] = cleaned_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e501fa-ad06-479b-b231-7fd7a509f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean df for future use\n",
    "question_df.to_csv('question_df.csv', index=False)\n",
    "\n",
    "level_1_df = question_df[question_df['difficulty']== 1]\n",
    "level_2_df = question_df[question_df['difficulty']== 2]\n",
    "level_3_df = question_df[question_df['difficulty']== 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e19983-67d1-4035-aaff-fa155d13500a",
   "metadata": {},
   "source": [
    "## Chatbot\n",
    "This video explained how to use api the best: https://www.youtube.com/watch?v=Si0vFx_dJ5Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1849e6a-b455-4a52-bb86-c007f97c5ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tool bot is designed to be the tool-using feature of the chat bot. During the session it will be a second instance of GPT-3.5 that can use tools\n",
    "#This gives pretty consistent behavior\n",
    "#save the system_content as a text file and load a variable to make code cleaner\n",
    "def tool_bot(prompt, history=[]):\n",
    "    messages =[\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": '''\n",
    "        You are a hyper intelligent robot that understands context, but your default response is the following:\n",
    "        \n",
    "        Resonse: xxxxx\n",
    "        \n",
    "        The only words you can use are the words below based on the provided condition below. \n",
    "        To be clear, If none of the conditions are met you are to respond with \"\"\" xxxxx \"\"\". You only respond with the following words when conditions are met. \n",
    "        Take your time to think this out.\n",
    "\n",
    "        Response Word: TEST \n",
    "        Condition: user asks to be tested (or any synonym of testing). Only do this when asked explicitly when user asks for a test.\n",
    "\n",
    "        Response Word: HINT\n",
    "        Condition: user asks to be given a hint or asks for help (or any synonym of hint)\n",
    "\n",
    "        Response Word: xxxxx\n",
    "        Condition: This is the default response when TEST or HINT are not appropriate\n",
    "\n",
    "        Response Word: LEVEL 1\n",
    "        Condition: If the user resonds with the numerical level of question they want (in this case \"\"\"1\"\"\"), please issue command \"\"\"LEVEL 1\"\"\". Please read the user input very carefully. If user is returning numbers in context of something calculation or code, please ignore.\n",
    "        Example user inputs include: \"\"\"\"level 1\"\"\"\", \"\"\" 1 \"\"\"\", \"lvl 1\", \"one\", \"I'd like level 1\" etc\n",
    "\n",
    "        Response Word: LEVEL 2\n",
    "        Condition: The user responds with the numerical level of question (in this case  \"\"\"2\"\"\" ). Please read the user input very carefully. If user is returning numbers in context of something calculation or code, please ignore.\n",
    "        Examples include: \"\"\"\"level 2\"\"\"\", \"\"\" 2 \"\"\"\", \"lvl 2\", \"two\", \"I'd like level 2\" etc\n",
    "\n",
    "        Response Word: LEVEL 3\n",
    "        Condition: The user responds with a numerical level of question ( in this case \"\"\"3\"\"\"). Please read the user input very carefully. If user is returning numbers in context of something calculation or code, please ignore.\n",
    "        Examples include: \"\"\"\"level 3\"\"\"\", \"\"\" 3 \"\"\"\", \"lvl 3\", \"three\", \"I'd like level 3\" etc\n",
    "\n",
    "     \n",
    "        \n",
    "        '''}]\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\") ##This isn't working for some reason \n",
    "   \n",
    "    \n",
    "    messages.append({'role': 'user', 'content': f'Here is my question: {prompt}'})#using f string to avoid prompt injections\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0, #play with temp to get more factual responses\n",
    "        max_tokens=10,#further limit output\n",
    "        top_p=0,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    # print(response) #print this in the CLI or notebook. This helps with understanding how the response json is structured for further customization\n",
    "    system_message = response['choices'][0]['message']['content'] #this is parsing the json file that is the response reponse. you take the first item in choices list (a list of dictionaries), go to message key, and then go to content key \n",
    "    # messages.append(({'role':'assistant', 'content': system_message}))      #dont need this for this bot\n",
    "    print(system_message)  \n",
    "    return system_message\n",
    "\n",
    "#testing tool_bot\n",
    "prompt = input()\n",
    "tool_bot(prompt=prompt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15531f95-536a-43c6-83f5-e2445dfac08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The main chotbot. it will have a nested openai api call in the form of the tool_bot function\n",
    "# Which will trigger some either grabbing data from questions database\n",
    "# \n",
    "from dotenv import load_dotenv\n",
    "#may need to repeat commands to ensure that it doesn't deviate from the behavior\n",
    "\n",
    "#global list of messages. \n",
    "messages =[\n",
    "        {\"role\": \"system\",\"content\": \"\"\"\n",
    "        You are an data science tutor with 20+ years of experience but you also follow instructions very well. \n",
    "        You are speaking to a student who has 0-5 years of experience in the data science field.\n",
    "        Here are some instructions for you:\n",
    "        \n",
    "        1. You will be given access to a question database which has Python questions, answers and \n",
    "        hints which vary between 3 levels of difficulty. If user asks you for a question level that is not 1, 2, or 3, then prompt them to give you a level between 1 and 3.\n",
    "        2. Once you are given the level of the question, you will provide a question. Ask the student to respond with computer code and or non-code answer.\n",
    "        The user will ask for hint, clarification of the question, or submit an answer. \n",
    "        3. When given a code or non-code answer, you will compare the answer to questions from the database and determine. You will show your work and think this out, step by step. Only execute this instruction in context of a coding question given to the user\n",
    "        if the student got it correct or incorrect and tell them explicitly what they did correctly and incorrectly in the following format:\n",
    "                \n",
    "        - Output '''Correct''' if the answer is the same as the answer you have. Show your work, step by step. Think this out, step by step. if answer does not \n",
    "        - Output '''Incorrect''' if answer is not correct \n",
    "\n",
    "        In the case of a code snippet submitted in response to a question, evaluate if the code would behave the same way as the code \n",
    "        provided by the answer key. Use your best judgement.\n",
    "\n",
    "        4. The student could have questions about a data science topic. Use your vast knowledge in data science and explain it to them. You can ask them if \n",
    "        they want a simple or detailed explanationation.\n",
    "        \n",
    "        Take as much time as you need to think this out. Think this out very carefully and do not deviate from your role as a data science tutor under no \n",
    "        circumstances.\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"}]\n",
    "#setting global variables, such that when I run my ai_chat function, hint is stored.\n",
    "#the only way to store memory outside of a function based on action happening within a function without using \n",
    "#return statement is to use mutable objects. initiate an empty list and then add or replace items in that list\n",
    "# we store the 0 index with an placeholder '' string so that we don't get index error for index being out of range. \n",
    "hint = ['']\n",
    "py_hint = ['']\n",
    "def ai_chat(prompt, history):\n",
    "    \n",
    "    #should I start with an assistant message to help the user get started?]#list of messages that get passed in to start convo, will also save messages here\n",
    "\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\") ##This isn't working for some reason \n",
    "    \n",
    "    messages.append({'role': 'user', 'content': f'{prompt}'}) #f string to avoid prompt injection errors from user\n",
    "  \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=1, #play with temp to get more factual responses\n",
    "        max_tokens=500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "\n",
    "\n",
    "    tool_response = tool_bot(prompt) #this is another instance of OpenAI (basically another agent) to issue commands\n",
    "    #initating empty variables for use later:\n",
    "  \n",
    "   \n",
    "    if tool_response == 'TEST':\n",
    "        print('testing TEST')\n",
    "        system_message = ('What level would you like? Please choose level 1, 2, or 3.')\n",
    "        # ask for level between 1 - 3\n",
    "        # load filtered data frame of question of that level\n",
    "        # make this the assistant message\n",
    "    elif tool_response == 'LEVEL 1':\n",
    "        random_row = level_1_df.sample(n=1)\n",
    "        question[0] = random_row['question'].to_list()\n",
    "        hint[0] = random_row['hint'].to_list()\n",
    "        py_hint[0] = random_row['python_hint'].to_list()\n",
    "        py_solution[0] = random_row['python_solution'].to_list()\n",
    "        system_message = f'''Here is your question:\n",
    "        \n",
    "        {question[0]}\n",
    "        \n",
    "        Please answer to the best of your ability in Python. If you need a hint don't hesistate to ask for one. \n",
    "        You can also ask me questions about a certain topic and I will do my best to help you. \n",
    "        \n",
    "        '''\n",
    "        # return system_message #perhaps storing these as attributes of an object is better?\n",
    "    elif tool_response == 'HINT': #########################################################################################################\n",
    "        # output both code and non-code hints\n",
    "        system_message = f'''Here is your hint: \n",
    "\n",
    "        {hint[0]}\n",
    "\n",
    "        {py_hint[0]}\n",
    "\n",
    "        If you have anymore questions let me know, otherwise please submit your answer.\n",
    "        '''\n",
    "    # Add a nested \"explain bot\" functionality? for MVP perhaps best to stick with relying GPT prompt engineering    \n",
    "    else:\n",
    "        system_message = response['choices'][0]['message']['content']\n",
    "    # hint = '' #this is parsing the json file that is the response reponse. you take the first item in choices list (a list of dictionaries), go to message key, and then go to content key \n",
    "    \n",
    "    \n",
    "    print(f'''\n",
    "    \n",
    "    MESSAGE: {messages}\n",
    "    \n",
    "    RESPONSE:{response}\n",
    "    \n",
    "    ''') #print this in the CLI or notebook. This helps with understanding how the response json is structured for further customization\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "    #if keyword command in system_message, \n",
    "    #first assistant message should be what level (and language) do you want?\n",
    "    #call a function that outputs a random row in questions dataframe based on level (and language)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    messages.append(({'role':'assistant', 'content': system_message}))\n",
    "    # messages=[] ##to clear memory and reset tokens maybe need to do this after adding save function for chat history and if token count is getting close to 4000. \n",
    "    \n",
    "    if 'hint' in locals():\n",
    "        return system_message, hint\n",
    "    else:\n",
    "        return system_message\n",
    "    \n",
    "#gradio interface fxn\n",
    "# def chatbot(input, history):\n",
    "#     history = history or []\n",
    "#     output = ai_chat(input)\n",
    "#     history.append([input, output])\n",
    "#     return history\n",
    "# gr.ChatInterface returns a ui that requires a function that takes two args, user input and a list that is something like user input and bot response\n",
    "demo = gr.ChatInterface(\n",
    "    fn=ai_chat, \n",
    "    submit_btn = 'Submit', \n",
    "    retry_btn = 'Retry',\n",
    "    clear_btn = 'Clear',\n",
    "    title = 'AI Tutor',\n",
    "    #add a save convo button that can create html file that can then be printed like a pdf later\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa963a76-fbef-4b26-8e55-f56bbde4fef0",
   "metadata": {},
   "source": [
    "## A hint I found during my chat gpt session \"AI Tutor Chat\"\n",
    "You can assign a variable based on a conditional statement inside a function. However, any variable defined inside a function in Python is local to that function, and it can't be accessed outside of the function unless it's returned or made global. \n",
    "\n",
    "Here's how you can do it with a `return` statement:\n",
    "\n",
    "```python\n",
    "def check_condition(condition):\n",
    "    if condition:\n",
    "        result = \"The condition was True.\"\n",
    "    else:\n",
    "        result = \"The condition was False.\"\n",
    "    return result\n",
    "\n",
    "# usage\n",
    "my_result = check_condition(True)\n",
    "print(my_result)  # prints: The condition was True.\n",
    "```\n",
    "\n",
    "If you don't want to use a `return` statement, you have two options:\n",
    "\n",
    "1. **Use a global variable:** You can define a variable outside the function and use the `global` keyword inside the function to tell Python that you want to use the global variable.\n",
    "\n",
    "```python\n",
    "result = None\n",
    "\n",
    "def check_condition(condition):\n",
    "    global result\n",
    "    if condition:\n",
    "        result = \"The condition was True.\"\n",
    "    else:\n",
    "        result = \"The condition was False.\"\n",
    "\n",
    "# usage\n",
    "check_condition(True)\n",
    "print(result)  # prints: The condition was True.\n",
    "```\n",
    "\n",
    "2. **Use mutable data types:** If you use a mutable data type like a list or a dictionary, changes made inside the function will be reflected outside of it, because the function receives a reference to the original data, not a copy of it.\n",
    "\n",
    "```python\n",
    "def check_condition(condition, result):\n",
    "    if condition:\n",
    "        result.append(\"The condition was True.\")\n",
    "    else:\n",
    "        result.append(\"The condition was False.\")\n",
    "\n",
    "# usage\n",
    "my_result = []\n",
    "check_condition(True, my_result)\n",
    "print(my_result)  # prints: ['The condition was True.']\n",
    "```\n",
    "\n",
    "Each of these methods has its pros and cons. Using global variables can make code harder to understand and debug, especially in larger programs, because it's not immediately clear where the variable is being changed. Using mutable data types can make your code more complex, especially if the function needs to change multiple values. In general, using `return` is the simplest and most straightforward way to get data out of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ae92e0-055a-4c3d-9592-d4d0baca541a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444ca52-2c31-4c04-be07-650b0d5eafbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9155b36-a8a4-4177-b329-bc081bec1dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123c812b-b23e-41bc-ba1d-f5bb8990aed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add functionality that tracks tokens and keeps system message, but deletes or summarizes conversation into a few lines, and feeds resets token count back to where it was at beginning of convo.\n",
    "#FAQ database:\n",
    "#Save responses, create an openai instance that can read each entry column one at atime (to avoid token limit)\n",
    "# and categorize commonly asked responses...and save that as a csv for future analysis\n",
    "\n",
    "#Future functionality:\n",
    "#Human like responsiveness. randomized delayed timer\n",
    "#Voice optionality. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c6bcb-da39-408a-a0cb-05f494c35d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
